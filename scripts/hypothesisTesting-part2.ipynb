{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb108a1b-df5f-48a0-92d7-12833d20dc42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf960d04-58d6-460a-9453-1ad6d7a6f825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f2527-fc92-4595-b2fc-ff44343b0d43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# issue urls where we couldn't parse llm response\n",
    "file_path = '/path/to/input/files' % replace with real path\n",
    "removed_issue_urls_df = pd.read_csv(file_path)\n",
    "removed_issue_urls=removed_issue_urls_df['issue_url'].tolist()\n",
    "removed_issue_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5982f-df83-4cfb-a03a-c02535d3efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(removed_issue_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de41c07-d224-4476-beb6-e6a22f8f0b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_pred_llama = pd.read_csv(file_path)\n",
    "df_pred_llama = df_pred_llama[~df_pred_llama['issue_url'].isin(removed_issue_urls)]\n",
    "df_pred_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b2240-b3af-417d-b39f-55d7571d7691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_pred_qwen = pd.read_csv(file_path)\n",
    "df_pred_qwen= df_pred_qwen.rename(columns={'issue_id':'issue_url'})\n",
    "\n",
    "df_pred_qwen = df_pred_qwen[~df_pred_qwen['issue_url'].isin(removed_issue_urls)]\n",
    "df_pred_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7902a-90bf-434f-b81c-9c9e8e4e3538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c60a20-3066-4344-b4fa-ba020020a294",
   "metadata": {},
   "source": [
    "## LLM Prediction Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928987e-4582-4127-9e44-e5cb9d21fe4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "train_issue_ids = pd.read_csv(file_path)['issue_id'].tolist()\n",
    "\n",
    "file_path = '/path/to/input/files' % replace with real path\n",
    "test_issue_ids = pd.read_csv(file_path)['issue_id'].tolist()\n",
    "train_issue_ids=[str(x) for x in train_issue_ids]\n",
    "test_issue_ids=[str(x) for x in test_issue_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc312667-d353-4eb7-af02-678e72b0c5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_unified_pred_llama = pd.read_csv(file_path)\n",
    "df_unified_pred_llama['issue_id']=df_unified_pred_llama['issue_id'].astype(str)\n",
    "df_train_pred_llama = df_unified_pred_llama[df_unified_pred_llama['issue_id'].isin(train_issue_ids)]\n",
    "df_test_pred_llama = df_unified_pred_llama[~df_unified_pred_llama['issue_id'].isin(train_issue_ids)]\n",
    "df_test_pred_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250d5d7-6f30-4a07-8f0d-1ae974a3b8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_unified_pred_qwen = pd.read_csv(file_path)\n",
    "df_unified_pred_qwen['issue_id']=df_unified_pred_qwen['issue_id'].astype(str)\n",
    "df_train_pred_qwen = df_unified_pred_qwen[df_unified_pred_qwen['issue_id'].isin(train_issue_ids)]\n",
    "df_test_pred_qwen = df_unified_pred_qwen[~df_unified_pred_qwen['issue_id'].isin(train_issue_ids)]\n",
    "df_test_pred_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c61133-2ac2-458c-a339-47439ee2ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Llama toxicity score statistics on train set:\")\n",
    "print(df_train_pred_llama['toxicity_score'].describe())\n",
    "\n",
    "print()\n",
    "print(\"Llama toxicity score statistics on test set:\")\n",
    "print(df_test_pred_llama['toxicity_score'].describe())\n",
    "\n",
    "print()\n",
    "print(\"Qwen toxicity score statistics on train set:\")\n",
    "print(df_train_pred_qwen['toxicity_score'].describe())\n",
    "\n",
    "print()\n",
    "print(\"Qwen toxicity score statistics on test set:\")\n",
    "print(df_test_pred_qwen['toxicity_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a3df3-c84b-4182-a450-66da70def357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_comments = pd.read_csv(file_path)\n",
    "df_comments = df_comments[~df_comments['issue_url'].isin(removed_issue_urls)]\n",
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb94dd1-9002-4695-ab3f-6b85fd84ae49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_comments.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707a7c8-3b81-4955-820b-6b05cdfbb81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_conv = pd.read_csv(file_path)\n",
    "df_conv = df_conv[~df_conv['issue_url'].isin(removed_issue_urls)]\n",
    "df_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de5486-b367-4325-af81-de70807ce002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_conv.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d31fa-e789-4659-ac63-b65246d237b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the correct verified converasations by the verifier\n",
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_incorrect = pd.read_csv(file_path)\n",
    "\n",
    "df_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9ed96-4187-4c5f-88f2-3be4959786f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Llama predicted toxic {sum(df_incorrect['toxicity_score_llama']>=0.3)}\")\n",
    "print(f\"Qwen predicted toxic {sum(df_incorrect['toxicity_score_qwen']>=0.3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd151d-0bc0-4b1a-a9f6-98c026a2b4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Llama predicted toxic {df_incorrect['is_toxic_llm_pred_llama'].sum()}\")\n",
    "print(f\"Qwen predicted toxic {df_incorrect['is_toxic_llm_pred_qwen'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86685fdc-4fc9-4b70-8b80-33f32132dc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the correct verified converasations by the verifier\n",
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_correct = pd.read_csv(file_path)\n",
    "df_correct = df_correct.rename(columns= {\n",
    "    'is_toxic_llm_pred_llama':'is_toxic'\n",
    "})\n",
    "df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0e783-e480-425a-bdc5-49b0314229bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435a71c-e566-466a-8a79-83d3b3e24fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/path/to/input/files' % replace with real path\n",
    "\n",
    "df_manual_annotated = pd.read_csv(file_path)\n",
    "df_manual_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62964560-ef87-430e-9ed3-5a38cb5fb459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labelled_combined = pd.concat([df_correct[['issue_url', 'is_toxic']], df_manual_annotated], axis=0, ignore_index=True)\n",
    "df_labelled_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc912397-b59a-4477-ad27-6f9441fa957c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe032a-dd98-45fb-8c7b-89787a6bfe41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labelled_combined['is_toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce046a-64a8-414f-9cc8-f95246bb11e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1b8b1-cf97-4960-b31c-c337f346ec1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_conv_merged = df_conv.merge(df_labelled_combined, on='issue_url', how='inner')\n",
    "df_conv_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9e271-8825-41ab-98ae-f8024a1313b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxic_df=df_conv_merged[df_conv_merged['is_toxic']==1]\n",
    "toxic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880647cd-ece3-4684-a108-b73319df7b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxic_urls = toxic_df['issue_url'].tolist()\n",
    "len(toxic_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67f094-fd42-4dd6-801c-e096a237a6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a446da6-f7a7-4a61-a1c3-5fcbc5a1f351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_comments = df_comments[df_comments['issue_url'].isin(correct_urls)].reset_index(drop=True)\n",
    "# del df_comments\n",
    "# df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df900ce-a87a-4afa-af78-3cce192c2230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_toxic_conv_comments = df_comments[df_comments['issue_url'].isin(toxic_urls)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fe07f-78ee-49e7-8411-d225de7f0376",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hypothesis #2 (Saveski et al): We find a clear positive relationship between size and toxicity. Larger trees tend to be more toxic in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90017871-f093-4c18-98f5-f87f8e60a5ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def extract_mentioned_users(text):\n",
    "    \"\"\"Extract all users mentioned with @username in the comment text.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    # Pattern to match @username (alphanumeric characters and hyphens)\n",
    "    pattern = r'@([a-zA-Z0-9-]+)'\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "def create_mention_graphs(df):\n",
    "    \"\"\"Create a directed graph for each issue based on user mentions.\"\"\"\n",
    "    # Group comments by issue_url\n",
    "    issue_groups = df.groupby('issue_url')\n",
    "    \n",
    "    # Store graphs for each issue along with the issue_url\n",
    "    issue_graphs = {}\n",
    "    \n",
    "    for issue_url, group in issue_groups:\n",
    "        # Create a directed graph for this issue\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add all users from this issue as nodes (even if they don't mention anyone)\n",
    "        for user in group['user'].unique():\n",
    "            G.add_node(user)\n",
    "        \n",
    "        # Process each comment to add edges for mentions\n",
    "        for _, row in group.iterrows():\n",
    "            commenter = row['user']\n",
    "            mentioned_users = extract_mentioned_users(row['body'])\n",
    "            \n",
    "            # Add edges from commenter to each mentioned user\n",
    "            for mentioned in mentioned_users:\n",
    "                # Only add edge if the mentioned user exists in our dataset for this issue\n",
    "                if mentioned in group['user'].values:\n",
    "                    G.add_edge(commenter, mentioned)\n",
    "        \n",
    "        # Store the graph with the issue_url as key\n",
    "        issue_graphs[issue_url] = G\n",
    "    \n",
    "    return issue_graphs\n",
    "\n",
    "def calculate_deepest_paths(issue_graphs):\n",
    "    \"\"\"Calculate the length of the longest path in each graph.\"\"\"\n",
    "    path_lengths = {}\n",
    "    \n",
    "    for issue_url, G in issue_graphs.items():\n",
    "        # Find the longest path length in the graph\n",
    "        if len(G.nodes()) <= 1:  # No path if 0 or 1 node\n",
    "            path_lengths[issue_url] = 0\n",
    "        else:\n",
    "            # Check if the graph is a DAG (Directed Acyclic Graph)\n",
    "            try:\n",
    "                # For DAGs, we can find the longest path\n",
    "                longest_path_length = nx.dag_longest_path_length(G)\n",
    "                path_lengths[issue_url] = longest_path_length\n",
    "            except nx.NetworkXUnfeasible:\n",
    "                # If there are cycles, use the more general approach\n",
    "                # Find all simple paths between all pairs of nodes and get the longest\n",
    "                all_path_lengths = []\n",
    "                \n",
    "                for source in G.nodes():\n",
    "                    for target in G.nodes():\n",
    "                        if source != target:\n",
    "                            try:\n",
    "                                # Get all simple paths from source to target\n",
    "                                paths = list(nx.all_simple_paths(G, source, target))\n",
    "                                if paths:\n",
    "                                    # Find the longest path length\n",
    "                                    max_path_length = max(len(path) - 1 for path in paths)\n",
    "                                    all_path_lengths.append(max_path_length)\n",
    "                            except nx.NetworkXNoPath:\n",
    "                                continue\n",
    "                \n",
    "                path_lengths[issue_url] = max(all_path_lengths) if all_path_lengths else 0\n",
    "    \n",
    "    return path_lengths\n",
    "\n",
    "def create_path_length_dataframe(issue_graphs):\n",
    "    \"\"\"Create a dataframe with issue_url and deepest path length.\"\"\"\n",
    "    path_lengths = calculate_deepest_paths(issue_graphs)\n",
    "    \n",
    "    # Create dataframe\n",
    "    df_path_lengths = pd.DataFrame({\n",
    "        'issue_url': list(path_lengths.keys()),\n",
    "        'deepest_path_length': list(path_lengths.values())\n",
    "    })\n",
    "    \n",
    "    return df_path_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11bba5-ec8a-4c93-b41d-d489f54aaac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create graphs for each issue\n",
    "issue_graphs = create_mention_graphs(df_comments)\n",
    "\n",
    "# Create dataframe with issue_url and deepest path length\n",
    "df_path_lengths = create_path_length_dataframe(issue_graphs)\n",
    "\n",
    "# Print the result\n",
    "print(\"Dataframe with issue URLs and deepest path lengths:\")\n",
    "df_path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb949f95-888b-4fce-bf39-3e19e0e8ea02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_path_lengths['deepest_path_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b641e-3924-4ee5-a488-1599cd4e02a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_path_lengths[df_path_lengths['deepest_path_length']>=6]['issue_url'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c49062e-c9d9-4e9a-99d3-e4b2fbeba905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df_conv_merged[df_conv_merged['issue_url']=='https://api.github.com/repos/flutter/flutter/issues/154241']\n",
    "df_test.to_csv('7_mention_conv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879dbd1-3796-4669-90c1-2e4c9bec8046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['is_toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39148ef-8907-4e18-8126-30e9a5cc5289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_toxicity_by_path_length(df_path_lengths, df_correct_filtered):\n",
    "    \"\"\"\n",
    "    Analyze the percentage of toxic issues for each deepest_path_length category.\n",
    "    \n",
    "    Parameters:\n",
    "    df_path_lengths: DataFrame with issue_url and deepest_path_length\n",
    "    df_correct_filtered: DataFrame with issue_url and is_toxic\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with analysis results\n",
    "    \"\"\"\n",
    "    # Merge the two dataframes on issue_url\n",
    "    merged_df = pd.merge(df_path_lengths, df_correct_filtered, on='issue_url', how='inner')\n",
    "    \n",
    "    # Calculate the total number of toxic issues\n",
    "    total_toxic_issues = merged_df[merged_df['is_toxic'] == True].shape[0]\n",
    "    \n",
    "    # Group by deepest_path_length and calculate toxicity metrics\n",
    "    toxicity_by_path = merged_df.groupby('deepest_path_length').agg(\n",
    "        total_issues=('issue_url', 'count'),\n",
    "        toxic_issues=('is_toxic', lambda x: sum(x == True)),\n",
    "        non_toxic_issues=('is_toxic', lambda x: sum(x == False))\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate percentages\n",
    "    toxicity_by_path['toxic_percentage_within_category'] = (toxicity_by_path['toxic_issues'] / \n",
    "                                                           toxicity_by_path['total_issues'] * 100).round(2)\n",
    "    \n",
    "    toxicity_by_path['percentage_of_all_toxic_issues'] = (toxicity_by_path['toxic_issues'] / \n",
    "                                                         total_toxic_issues * 100).round(2)\n",
    "    \n",
    "    return toxicity_by_path\n",
    "\n",
    "def visualize_toxicity_distribution(toxicity_by_path):\n",
    "    \"\"\"Create visualizations for the toxicity distribution by path length.\"\"\"\n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "    \n",
    "    # Plot 1: Percentage of toxic issues within each path length category\n",
    "    sns.barplot(x='deepest_path_length', y='toxic_percentage_within_category', \n",
    "                data=toxicity_by_path, ax=ax1, palette='Blues_d')\n",
    "    # ax1.set_title('Percentage of Toxic Issues Within Each Path Length Category')\n",
    "    ax1.set_xlabel('Deepest Path Length')\n",
    "    ax1.set_ylabel('Percentage of Issues That Are Toxic')\n",
    "    # Add \"(a)\" label at the bottom-middle of the first subplot\n",
    "    ax1.text(0.5, -0.18, \"(a)\", transform=ax1.transAxes, \n",
    "             ha='center', va='center', fontsize=16)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, row in enumerate(toxicity_by_path.itertuples()):\n",
    "        ax1.text(i, row.toxic_percentage_within_category + 1, \n",
    "                f\"{row.toxic_percentage_within_category}%\", \n",
    "                ha='center')\n",
    "    \n",
    "    # Plot 2: Distribution of all toxic issues by path length\n",
    "    sns.barplot(x='deepest_path_length', y='percentage_of_all_toxic_issues', \n",
    "                data=toxicity_by_path, ax=ax2, palette='Reds_d')\n",
    "    # ax2.set_title('Distribution of All Toxic Issues by Path Length')\n",
    "    ax2.set_xlabel('Deepest Path Length')\n",
    "    ax2.set_ylabel('Percentage of All Toxic Issues')\n",
    "      # Add \"(a)\" label at the bottom-middle of the first subplot\n",
    "    ax2.text(0.5, -0.18, \"(b)\", transform=ax2.transAxes, \n",
    "             ha='center', va='center', fontsize=16)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, row in enumerate(toxicity_by_path.itertuples()):\n",
    "        ax2.text(i, row.percentage_of_all_toxic_issues + 1, \n",
    "                f\"{row.percentage_of_all_toxic_issues}%\", \n",
    "                ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./output/toxicity_by_path_length.png', dpi=1200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main function\n",
    "def analyze_toxicity_path_relationship(df_path_lengths, df_correct_filtered):\n",
    "    \"\"\"Main function to analyze and visualize the relationship between path length and toxicity.\"\"\"\n",
    "    # Perform the analysis\n",
    "    toxicity_analysis = analyze_toxicity_by_path_length(df_path_lengths, df_correct_filtered)\n",
    "    \n",
    "    # Print the results table\n",
    "    print(\"Analysis of Toxicity by Deepest Path Length:\")\n",
    "    print(toxicity_analysis)\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(f\"- Total toxic issues analyzed: {toxicity_analysis['toxic_issues'].sum()}\")\n",
    "    \n",
    "    # For each path length, print the percentage of all toxic issues\n",
    "    for _, row in toxicity_analysis.iterrows():\n",
    "        print(f\"- {row['percentage_of_all_toxic_issues']}% of the overall total toxic issues have deepest_path_length {row['deepest_path_length']}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    visualize_toxicity_distribution(toxicity_analysis)\n",
    "    \n",
    "    return toxicity_analysis\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df_path_lengths and df_correct_filtered are already defined\n",
    "    \n",
    "    toxicity_analysis = analyze_toxicity_path_relationship(df_path_lengths, df_conv_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02010eb4-0404-4a62-8d01-5bdb98cc99c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Main function to analyze and visualize the relationship between path length and toxicity.\"\"\"\n",
    "# Perform the analysis\n",
    "toxicity_analysis = analyze_toxicity_by_path_length(df_path_lengths, df_conv_merged)\n",
    "\n",
    "# Print the results table\n",
    "print(\"Analysis of Toxicity by Deepest Path Length:\")\n",
    "print(toxicity_analysis)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"- Total toxic issues analyzed: {toxicity_analysis['toxic_issues'].sum()}\")\n",
    "\n",
    "# For each path length, print the percentage of all toxic issues\n",
    "for _, row in toxicity_analysis.iterrows():\n",
    "    print(f\"- {row['percentage_of_all_toxic_issues']}% of the overall total toxic issues have deepest_path_length {row['deepest_path_length']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f4a5f-4963-4ddd-a704-4e195ef203ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21b85e8-1181-47c9-8878-576554ee5fc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hypothesis #10(Ferreira et al.): Use of capital letters in uncivil threads\n",
    "**Quote:** “Contributors tend to express Annoyance and Bitter frustration in issue discussions when they use capital letters to emphasize something in a frustrating way, when someone is using abusive language to express their opinion, when injustice makes the other person feel unable to defend herself/himself, and when the speaker is strongly irritated by something impossible to do in the speaker’s opinion.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e60d6-51a3-4250-b0a1-f6a26b345ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def analyze_capital_letters(df):\n",
    "    \"\"\"\n",
    "    Analyzes a dataframe of comments to calculate:\n",
    "    1) Total number of all-capital-letter comments in each conversation\n",
    "    2) Total number of comments where at least one word is all capital letters\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with columns 'issue_url' and 'body'\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Results dataframe with capital letter metrics by issue\n",
    "    \"\"\"\n",
    "    # Function to check if a comment is entirely in capital letters\n",
    "    def is_all_caps(text):\n",
    "        # Check if text contains any letters\n",
    "        if not re.search('[a-zA-Z]', text):\n",
    "            return False\n",
    "        # Check if all letters are uppercase\n",
    "        return all(c.isupper() for c in text if c.isalpha())\n",
    "    \n",
    "    # Function to check if any word in a comment is entirely in capital letters\n",
    "    def has_caps_word(text):\n",
    "        words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "        # Check if any word has at least four letters\n",
    "        # to remove single letter word like \"A big cat\"\n",
    "        # and to remove abbreviations here like, AI, TCP, MCP, ...             \n",
    "        # and all letters are uppercase\n",
    "        return any(len(word) >= 4 and all(c.isupper() for c in word) for word in words)\n",
    "    \n",
    "    # Create temporary columns with our calculated values\n",
    "    df['is_all_caps'] = df['body'].apply(is_all_caps)\n",
    "    df['has_caps_word'] = df['body'].apply(has_caps_word)\n",
    "    \n",
    "    # Group by issue_url and count the occurrences\n",
    "    results = df.groupby('issue_url').agg(\n",
    "        total_comments=('body', 'count'),\n",
    "        all_caps_comments=('is_all_caps', 'sum'),\n",
    "        comments_with_caps_word=('has_caps_word', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate percentages\n",
    "    results['all_caps_percentage'] = (results['all_caps_comments'] / results['total_comments'] * 100).round(2)\n",
    "    results['caps_word_percentage'] = (results['comments_with_caps_word'] / results['total_comments'] * 100).round(2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "results_df = analyze_capital_letters(df_comments)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc501144-5148-460e-b8f9-11c288f47075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxic_urls = df_conv_merged[df_conv_merged['is_toxic']==True ]['issue_url'].tolist()\n",
    "df_toxic_cap = results_df[results_df['issue_url'].isin(toxic_urls)]\n",
    "\n",
    "print(\"Analysis of the percentage of comments containig at least one all capital letter word in the toxic conversations\")\n",
    "print(df_toxic_cap['caps_word_percentage'].describe())\n",
    "\n",
    "non_toxic_urls = df_conv_merged[df_conv_merged['is_toxic']==False ]['issue_url'].tolist()\n",
    "df_non_toxic_cap = results_df[results_df['issue_url'].isin(non_toxic_urls)]\n",
    "print(\"Analysis of the percentage of comments containing at least one all capital letter word in the non-toxic conversations\")\n",
    "print(df_non_toxic_cap['caps_word_percentage'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97d723-e117-43bd-ac54-06cf52776b2e",
   "metadata": {},
   "source": [
    "## Hypothesis (Sarkar et al): Accepted PRs are less likely to encounter toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db005d44-e835-4fed-a611-e802701bccc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_issue_acceptance = pd.read_csv(\"./output/issue_acceptance_data_large_dataset.csv\")\n",
    "df_issue_acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807af6e-e774-43ed-845d-6c1dededfaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_issues = df_issue_acceptance[df_issue_acceptance['is_pull_req']==True].shape[0]\n",
    "total_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6fdd9-c76f-4916-b68a-c4f971534b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove the invalid issues\n",
    "df_issue_acceptance = df_issue_acceptance[~df_issue_acceptance['issue_url'].isin(removed_issue_urls)]\n",
    "df_issue_acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701ae13-07c7-47db-a8fe-a5dd7705dde1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064cf79-63bd-447f-b656-18091e1123ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pr_status = df_issue_acceptance[df_issue_acceptance['is_pull_req']==True]\n",
    "del df_issue_acceptance\n",
    "df_pr_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bfc4b-6079-43bb-9b2d-55a9b7232475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only take the pr issues that are in our labelled data\n",
    "df_pr_status = df_pr_status[df_pr_status['issue_url'].isin(df_conv_merged['issue_url'].tolist())]\n",
    "df_pr_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66257d11-61a7-4c01-be21-f15f3a9dc5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_conv_merged['is_toxic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47842e0f-331f-48cf-bd62-4f3bd0ed6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_pr_status and df_conv_merged are already loaded\n",
    "# Merge the dataframes based on issue_url\n",
    "merged_df = pd.merge(df_pr_status, df_conv_merged, on='issue_url', how='left')\n",
    "print(f\"Total pull request(PR) in our dataset {merged_df.shape[0]}\" )\n",
    "print(\"Among these,\")\n",
    "\n",
    "accepted_df =  merged_df[ merged_df['is_merged']==True]\n",
    "accepted_toxic_df = accepted_df[accepted_df['is_toxic']==True]\n",
    "print(\"\\nFrom accepted PR perspective,\")\n",
    "print(f'\\tOut of {accepted_df.shape[0]} accepted pr, {accepted_toxic_df.shape[0]} are toxic. Toxicity rate ={accepted_toxic_df.shape[0]/accepted_df.shape[0]*100:.2f}%')\n",
    "\n",
    "non_accepted_df =  merged_df[merged_df['is_merged']==False]\n",
    "non_accepted_toxic_df = non_accepted_df[non_accepted_df['is_toxic']==True]\n",
    "print(f'\\tOut of {non_accepted_df.shape[0]} non-accepted pr, {non_accepted_toxic_df.shape[0]} are toxic. Toxicity rate ={non_accepted_toxic_df.shape[0]/non_accepted_df.shape[0]*100:.2f}%')\n",
    "\n",
    "toxic_df =  merged_df[ merged_df['is_toxic']==True]\n",
    "toxic_accepted_df = toxic_df[toxic_df['is_merged']==True]\n",
    "print(\"\\nToxic PR perspective,\")\n",
    "print(f'\\tOut of {toxic_df.shape[0]} toxic pr, {toxic_accepted_df.shape[0]} are accepted. Acceptance rate ={toxic_accepted_df.shape[0]/toxic_df.shape[0]*100:.2f}%')\n",
    "\n",
    "nontoxic_df =  merged_df[merged_df['is_toxic']==False]\n",
    "nontoxic_df\n",
    "nontoxic_accepted_df = nontoxic_df[nontoxic_df['is_merged']==True]\n",
    "print(f'\\tOut of {nontoxic_df.shape[0]} non-toxic pr, {nontoxic_accepted_df.shape[0]} are accepted. Acceptance rate ={nontoxic_accepted_df.shape[0]/nontoxic_df.shape[0]*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd9c9c-c4bd-4203-a09f-befc8ebdc79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c973195-4218-45a6-a5d7-6fc0eff28ffa",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Hypothesis (Imran et al.) : Toxic conversations on GitHub tended to be longer, with a median of 11 comments versus 6 in the non-toxic conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100bb48-14a6-4e9d-a3eb-87db7cf62441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dcee0-6528-4633-8758-863c7df8c9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming df_conv is your dataframe with GitHub issue conversations\n",
    "# and toxic_issue_urls is a list of URLs identified as toxic\n",
    "\n",
    "# Step 1: Create a new column indicating if an issue is toxic\n",
    "\n",
    "# Step 2: Separate toxic and non-toxic issues\n",
    "toxic_issues = df_conv_merged[df_conv_merged['is_toxic'] == True]\n",
    "non_toxic_issues = df_conv_merged[df_conv_merged['is_toxic'] == False]\n",
    "\n",
    "# Step 3: Calculate summary statistics\n",
    "toxic_stats = toxic_issues['comments_count'].describe()\n",
    "non_toxic_stats = non_toxic_issues['comments_count'].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(\"Toxic Issues Statistics:\")\n",
    "print(toxic_stats)\n",
    "print(\"\\nNon-Toxic Issues Statistics:\")\n",
    "print(non_toxic_stats)\n",
    "\n",
    "# Step 4: Compare medians\n",
    "toxic_median = toxic_issues['comments_count'].median()\n",
    "non_toxic_median = non_toxic_issues['comments_count'].median()\n",
    "\n",
    "print(f\"\\nMedian comment count for toxic issues: {toxic_median}\")\n",
    "print(f\"Median comment count for non-toxic issues: {non_toxic_median}\")\n",
    "print(f\"Difference in medians: {toxic_median - non_toxic_median}\")\n",
    "\n",
    "# Step 5: Statistical test (Mann-Whitney U Test - non-parametric test for comparing medians)\n",
    "u_stat, p_value = stats.mannwhitneyu(toxic_issues['comments_count'], non_toxic_issues['comments_count'])\n",
    "print(f\"\\nMann-Whitney U Test: U={u_stat}, p-value={p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference is statistically significant (p < 0.05)\")\n",
    "else:\n",
    "    print(\"The difference is not statistically significant (p ≥ 0.05)\")\n",
    "\n",
    "# Step 6: Visualize the distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='is_toxic', y='comments_count', data=df_conv_merged)\n",
    "plt.title('Comment Count Comparison')\n",
    "plt.xlabel('Is Toxic')\n",
    "plt.ylabel('Number of Comments')\n",
    "\n",
    "# Histogram/KDE\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(toxic_issues['comments_count'], color='red', alpha=0.5, label='Toxic')\n",
    "sns.histplot(non_toxic_issues['comments_count'], color='blue', alpha=0.5, label='Non-Toxic')\n",
    "plt.title('Distribution of Comment Counts')\n",
    "plt.xlabel('Number of Comments')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Calculate effect size (Cohen's d)\n",
    "mean_diff = toxic_issues['comments_count'].mean() - non_toxic_issues['comments_count'].mean()\n",
    "pooled_std = np.sqrt((toxic_issues['comments_count'].var() + non_toxic_issues['comments_count'].var()) / 2)\n",
    "cohens_d = mean_diff / pooled_std\n",
    "\n",
    "print(f\"\\nEffect size (Cohen's d): {cohens_d}\")\n",
    "if abs(cohens_d) < 0.2:\n",
    "    print(\"Small effect size\")\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    print(\"Medium effect size\")\n",
    "else:\n",
    "    print(\"Large effect size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e7e0c-66ce-4b66-bbec-1062dab98be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5fde9-5ece-4129-8233-b4354cf79761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
